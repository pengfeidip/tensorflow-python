{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "第一层为卷积层, 卷积层_1的参数  \n",
    "input:  filter: \n",
    "        size: 5*5;  number: 6  channel:  1  \n",
    "output: feature map: \n",
    "        size 28*28, number 6; channel :1\n",
    "\"\"\"\n",
    "CONV1_FILTER_SIZE = 5\n",
    "CONV1_FILTER_CHANNEL = 1\n",
    "CONV1_FILTER_NUM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "第三层为卷积层, 卷积层_3的参数\n",
    "input: filter:\n",
    "       size 5 * 5   number 16 channel: 1\n",
    "output: feature map\n",
    "       size 10 * 10 number 16  channel: 1 \n",
    "       \n",
    "\"\"\"\n",
    "CONV3_FILTER_SIZE = 5\n",
    "CONV3_FILTER_CHANNEL = 1\n",
    "CONV3_FILTER_NUM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "第五层是一个卷积层, \n",
    "input: filter:\n",
    "        size 5 *5    number 120   channel: 1\n",
    "output: feature map\n",
    "        size 1    number 120  channel: 1\n",
    "\"\"\"\n",
    "CONV5_FILTER_SIZE = 5\n",
    "CONV5_FILTER_CHANNEL = 1\n",
    "CONV5_FILTER_NUM = 120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet_inference(inTensor):\n",
    "    \n",
    "    \"\"\"conv 1.  第一层为卷积层,有6个filter\n",
    "    input size: 32 * 32 * 1\n",
    "    output size: 28 * 28 * 6\n",
    "    \"\"\"\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal([CONV1_FILTER_SIZE,CONV1_FILTER_SIZE,CONV1_FILTER_CHANNEL, CONV1_FILTER_NUM],dtype=tf.float32))\n",
    "    conv1 = tf.nn.conv2d(inTensor, conv1_filter, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    conv1_bias = tf.Variable(tf.truncated_normal([CONV1_FILTER_NUM], dtype=tf.float32))\n",
    "    relu_1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "    \n",
    "    \"\"\"pooling 2.  \n",
    "     第2层为pooling层,与原始LetNet不同.原始的LeNet的pooling层有两个可训练参数\n",
    "     input size: 28 * 28 * 6\n",
    "     output size: 14 * 14 * 6\n",
    "    \"\"\"\n",
    "    pooling2 = tf.nn.avg_pool(relu_1, ksize=[1,2,2,1], strides=[1, 2, 2 ,1], padding=\"VALID\")\n",
    "    relu_2 = tf.nn.relu(pooling2)\n",
    "    \n",
    "    \n",
    "    \"\"\" conv 3  \n",
    "    第3层为卷积层,共16个filter. 与原始LeNet不同,原始的LeNet是部分连接\n",
    "    这里为了方便是,整体连接,详细情况见论文希捷\n",
    "    input size 14 * 14 * 6\n",
    "    out putsize 10 * 10 *16\n",
    "    \"\"\"\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal([5, 5, 6, 16]))\n",
    "    conv3_bias = tf.Variable(tf.truncated_normal([16]))\n",
    "    conv3 = tf.nn.conv2d(relu_2, conv3_filter, strides=[1,1,1,1],padding='VALID')\n",
    "    relu_3 =tf.nn.relu(tf.nn.bias_add(conv3, conv3_bias))\n",
    "    \n",
    "    \n",
    "    \"\"\"pooling 4  \n",
    "    第4层为pooling层, 与pooling 2 相同\n",
    "    input size:  10 * 10 * 16\n",
    "    output size: 5 * 5 * 16\n",
    "    \"\"\"\n",
    "    pooling4 = tf.nn.avg_pool(relu_3, ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"VALID\")\n",
    "    relu_4 = tf.nn.relu(pooling4)\n",
    "    \n",
    "    \"\"\"conv 5\n",
    "    第5层为conv层, 这一层与原始的LeNet-5是一致的\n",
    "    input size: 5 * 5 * 16\n",
    "    output size: 1 * 1 * 120\n",
    "    \"\"\"\n",
    "    conv5_filter = tf.Variable(tf.truncated_normal([5, 5, 16, 120]))\n",
    "    conv5_bias = tf.Variable(tf.truncated_normal([120]))\n",
    "    conv5 = tf.nn.conv2d(relu_4, conv5_filter, strides=[1,1,1,1],padding=\"VALID\")\n",
    "    relu_5 = tf.nn.relu(tf.nn.bias_add(conv5, conv5_bias))\n",
    "    \n",
    "    \"\"\"fc 6\n",
    "    第6层为fc层,与原始不太一致,因为我只在mnist上进性试验\n",
    "    input size: 1 * 1 * 120\n",
    "    output size: 1* 1* 10\n",
    "    \"\"\"\n",
    "    fc_weights = tf.Variable(tf.truncated_normal([120,10]))\n",
    "    fc_bias = tf.Variable(tf.truncated_normal([10]))\n",
    "    relu_5 = tf.reshape(relu_5, [1, 120])\n",
    "    relu_6 = tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(relu_5, fc_weights),fc_bias))\n",
    "    \n",
    "    \n",
    "    \"\"\"最后的输出单元\n",
    "    softmax分类器\n",
    "    \"\"\"\n",
    "    logits = tf.nn.softmax(relu_6)\n",
    "    #result = tf.one_hot(tf.argmax(tf.transpose(logits)), 10)\n",
    "    return logits\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-4eea66d2ec37>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./input_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./input_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./input_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./input_data', one_hot=True, validation_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "ind = 10;\n",
    "test = mnist.train.images[ind, :]\n",
    "label = mnist.train.labels[ind, :]\n",
    "shaped = test.reshape((28, 28))\n",
    "padded = np.pad(shaped, ((2,2),(2,2)), \"constant\", constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.reshape(padded, (1, 32, 32, 1))\n",
    "result = LeNet_inference(im)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=label, logits=result )\n",
    "loss = tf.reduce_mean(cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "a = LeNet_inference(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04539683  0.12340137  0.04539683  0.12340137  0.04539683  0.12340137\n",
      "   0.12340137  0.12340137  0.12340137  0.12340137]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(result))\n",
    "    for i in range(100):\n",
    "        sess.run(train_op)\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "186px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

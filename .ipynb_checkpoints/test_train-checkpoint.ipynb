{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import Ipynb_importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-05ab45eebe5b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./input_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./input_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./input_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./input_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From G:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./input_data', one_hot=True, validation_size=500)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# network 设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\"\"\"\n",
    "第一层为卷积层, 卷积层_1的参数  \n",
    "input:  filter: \n",
    "        size: 5*5;  number: 6  channel:  1  \n",
    "output: feature map: \n",
    "        size 28*28, number 6; channel :1\n",
    "\"\"\"\n",
    "CONV1_FILTER_SIZE = 5\n",
    "CONV1_FILTER_CHANNEL = 1\n",
    "CONV1_FILTER_NUM = 6\n",
    "\n",
    "\"\"\"\n",
    "第三层为卷积层, 卷积层_3的参数\n",
    "input: filter:\n",
    "       size 5 * 5   number 16 channel: 1\n",
    "output: feature map\n",
    "       size 10 * 10 number 16  channel: 1 \n",
    "       \n",
    "\"\"\"\n",
    "CONV3_FILTER_SIZE = 5\n",
    "CONV3_FILTER_CHANNEL = 1\n",
    "CONV3_FILTER_NUM = 16\n",
    "\n",
    "\"\"\"\n",
    "第五层是一个卷积层, \n",
    "input: filter:\n",
    "        size 5 *5    number 120   channel: 1\n",
    "output: feature map\n",
    "        size 1    number 120  channel: 1\n",
    "\"\"\"\n",
    "CONV5_FILTER_SIZE = 5\n",
    "CONV5_FILTER_CHANNEL = 1\n",
    "CONV5_FILTER_NUM = 120\n",
    "\n",
    "\"\"\"\n",
    "设置一些训练参数\n",
    "\"\"\"\n",
    "BATCH_SIZE = 100;\n",
    "\n",
    "# LeNet_inference\n",
    "\n",
    "def LeNet_inference(inTensor):\n",
    "    \n",
    "    \"\"\"conv 1.  第一层为卷积层,有6个filter\n",
    "    input size: 32 * 32 * 1\n",
    "    output size: 28 * 28 * 6\n",
    "    \"\"\"\n",
    "    conv1_filter = tf.Variable(tf.truncated_normal([CONV1_FILTER_SIZE,CONV1_FILTER_SIZE,CONV1_FILTER_CHANNEL, CONV1_FILTER_NUM],dtype=tf.float32))\n",
    "    conv1 = tf.nn.conv2d(inTensor, conv1_filter, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    conv1_bias = tf.Variable(tf.truncated_normal([CONV1_FILTER_NUM], dtype=tf.float32))\n",
    "    relu_1 = tf.nn.relu(tf.nn.bias_add(conv1, conv1_bias))\n",
    "    \n",
    "    \"\"\"pooling 2.  \n",
    "     第2层为pooling层,与原始LetNet不同.原始的LeNet的pooling层有两个可训练参数\n",
    "     input size: 28 * 28 * 6\n",
    "     output size: 14 * 14 * 6\n",
    "    \"\"\"\n",
    "    pooling2 = tf.nn.avg_pool(relu_1, ksize=[1,2,2,1], strides=[1, 2, 2 ,1], padding=\"VALID\")\n",
    "    relu_2 = tf.nn.relu(pooling2)\n",
    "    \n",
    "    \n",
    "    \"\"\" conv 3  \n",
    "    第3层为卷积层,共16个filter. 与原始LeNet不同,原始的LeNet是部分连接\n",
    "    这里为了方便是,整体连接,详细情况见论文希捷\n",
    "    input size 14 * 14 * 6\n",
    "    out putsize 10 * 10 *16\n",
    "    \"\"\"\n",
    "    conv3_filter = tf.Variable(tf.truncated_normal([5, 5, 6, 16]))\n",
    "    conv3_bias = tf.Variable(tf.truncated_normal([16]))\n",
    "    conv3 = tf.nn.conv2d(relu_2, conv3_filter, strides=[1,1,1,1],padding='VALID')\n",
    "    relu_3 =tf.nn.relu(tf.nn.bias_add(conv3, conv3_bias))\n",
    "    \n",
    "    \n",
    "    \"\"\"pooling 4  \n",
    "    第4层为pooling层, 与pooling 2 相同\n",
    "    input size:  10 * 10 * 16\n",
    "    output size: 5 * 5 * 16\n",
    "    \"\"\"\n",
    "    pooling4 = tf.nn.avg_pool(relu_3, ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"VALID\")\n",
    "    relu_4 = tf.nn.relu(pooling4)\n",
    "    \n",
    "    \"\"\"conv 5\n",
    "    第5层为conv层, 这一层与原始的LeNet-5是一致的\n",
    "    input size: batch size * 5 * 5 * 16\n",
    "    output size: batch size * 1  120\n",
    "    \"\"\"\n",
    "    conv5_filter = tf.Variable(tf.truncated_normal([5, 5, 16, 120]))\n",
    "    conv5_bias = tf.Variable(tf.truncated_normal([120]))\n",
    "    conv5 = tf.nn.conv2d(relu_4, conv5_filter, strides=[1,1,1,1],padding=\"VALID\")\n",
    "    relu_5 = tf.nn.relu(tf.nn.bias_add(conv5, conv5_bias))\n",
    "\n",
    "    relu_5_shaped = tf.reshape(relu_5, [100, 120], name=\"relu_5_reshape\")#relu_5变为 batch size * 120\n",
    "    \n",
    "    \"\"\"fc 6\n",
    "    第6层为fc层,与原始不太一致,因为我只在mnist上进性试验\n",
    "    input size: batch size * 1 * 1 * 120\n",
    "    output size: batch size * 1 * 1 * 10\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "        \n",
    "    fc_weights = tf.Variable(tf.truncated_normal([120,10]))\n",
    "    fc_bias = tf.Variable(tf.truncated_normal([10]))\n",
    "\n",
    "    relu_6 = tf.nn.sigmoid(tf.nn.bias_add(tf.matmul(relu_5_shaped, fc_weights),fc_bias))\n",
    " \n",
    "    \n",
    "    \"\"\"最后的输出单元\n",
    "    softmax分类器\n",
    "    \"\"\"\n",
    "    #logits = tf.nn.softmax(relu_6)\n",
    "    #result = tf.one_hot(tf.argmax(tf.transpose(logits)), 10)\n",
    "    return relu_6\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练过程设计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10000 #迭代次数、\n",
    "LEARNING_RATE = 0.001  # larning rate\n",
    "\n",
    "\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[BATCH_SIZE, 32, 32, 1],name=\"input\")\n",
    "y_predicted = LeNet_inference(x);\n",
    "y_label = tf.placeholder(dtype=tf.float32, shape=[BATCH_SIZE, 10], name=\"label\")\n",
    "\n",
    "\"\"\"\n",
    "loss function and optimization \n",
    "\n",
    "\"\"\"\n",
    "loss_all = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_label, logits=y_predicted)\n",
    "loss = tf.reduce_mean(loss_all)\n",
    "train_op = tf.train.GradientDescentOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "loss_list = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52245\n",
      "2.47027\n",
      "2.4508\n",
      "2.4607\n",
      "2.39198\n",
      "2.35349\n",
      "2.31179\n",
      "2.30986\n",
      "2.31617\n",
      "2.37573\n",
      "2.3617\n",
      "2.30171\n",
      "2.42598\n",
      "2.30485\n",
      "2.30663\n",
      "2.32879\n",
      "2.29911\n",
      "2.39315\n",
      "2.2655\n",
      "2.2834\n",
      "2.19958\n",
      "2.34193\n",
      "2.25356\n",
      "2.2708\n",
      "2.24834\n",
      "2.32368\n",
      "2.28664\n",
      "2.2501\n",
      "2.20284\n",
      "2.29717\n",
      "2.34015\n",
      "2.22014\n",
      "2.3242\n",
      "2.23067\n",
      "2.28318\n",
      "2.1381\n",
      "2.26652\n",
      "2.18555\n",
      "2.21931\n",
      "2.16737\n",
      "2.20615\n",
      "2.23932\n",
      "2.16911\n",
      "2.2791\n",
      "2.1517\n",
      "2.18365\n",
      "2.2332\n",
      "2.17202\n",
      "2.12437\n",
      "2.2332\n",
      "training is end\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(20000):\n",
    "        xs,ys = mnist.train.next_batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "        #reshape the input \n",
    "        xs.shape = (BATCH_SIZE, 28, 28, 1)\n",
    "        xs = np.pad(xs, ((0, 0), (2, 2), (2, 2), (0, 0)), 'constant', constant_values= 0)\n",
    "\n",
    "        _, loss_np = sess.run([train_op, loss], feed_dict={x:xs, y_label:ys})\n",
    "        if i% 500 == 0:\n",
    "            print(loss_np)\n",
    "    print(\"training is end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([])\n",
    "axes_handle, = plt.plot(test)\n",
    "\n",
    "import time\n",
    "for i in range(20):\n",
    "    time.sleep(0.5)\n",
    "    axes_handle.set_xdata(i)\n",
    "    axes_handle.set_ydata(i+10)\n",
    "    plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 784)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create correctly shaped tuple from ((0, 0), (1, 1))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mG:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_normalize_shape\u001b[1;34m(ndarray, shape, cast_to_int)\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mshape_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36mbroadcast_to\u001b[1;34m(array, shape, subok)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \"\"\"\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_broadcast_to\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\lib\\stride_tricks.py\u001b[0m in \u001b[0;36m_broadcast_to\u001b[1;34m(array, shape, subok, readonly)\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'multi_index'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'refs_ok'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'zerosize_ok'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mextras\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         op_flags=[op_flag], itershape=shape, order='C').itviews[0]\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_view_as_subclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2) and requested shape (3,2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-d1737c5388d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'constant'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstant_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[0mnarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m     \u001b[0mpad_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m     allowedkwargs = {\n",
      "\u001b[1;32mG:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_validate_lengths\u001b[1;34m(narray, number_elements)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1079\u001b[0m     \"\"\"\n\u001b[1;32m-> 1080\u001b[1;33m     \u001b[0mnormshp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_normalize_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_elements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1081\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormshp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         \u001b[0mchk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda\\installCatalog\\envs\\tensorflow_cpu\\lib\\site-packages\\numpy\\lib\\arraypad.py\u001b[0m in \u001b[0;36m_normalize_shape\u001b[1;34m(ndarray, shape, cast_to_int)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[0mfmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Unable to create correctly shaped tuple from %s\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     \u001b[1;31m# Cast if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unable to create correctly shaped tuple from ((0, 0), (1, 1))"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4, 5, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "143px",
    "width": "234px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
